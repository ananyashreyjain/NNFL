{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kjDOBaHIpsX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vjqc6PoYJFmL"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8bLloj6JRF3"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/content/drive/My Drive/train.csv' )\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "la0B4q_nOGLO"
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:].to_numpy()\n",
    "Y = df.iloc[:,0].to_numpy()\n",
    "# Given = (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "fac_exp = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Suprise\", \"Neutral\"]\n",
    "\n",
    "def int_pixels(X, shape=(48,48)):\n",
    "    img = [list(map(int,df['pixels'].iloc[index].split(' '))) for index in range(X.shape[0])]\n",
    "    img = np.array(img).reshape((-1, shape[0], shape[1], 1))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CM1rPOqyOc4H"
   },
   "outputs": [],
   "source": [
    "X = int_pixels(X)\n",
    "print(f\"No of pictures = %d, No of emotions = %d\" % (X.shape[0],Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SG52ZpumeYt"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,4, figsize=(10, 10))\n",
    "k = 0\n",
    "for i in range(4): \n",
    "    for j in range(4): \n",
    "        ax[i][j].imshow(X.reshape(-1,48,48)[k]) \n",
    "        ax[i][j].set_title(fac_exp[Y[k]]) \n",
    "        ax[i][j].axis(\"off\")\n",
    "        k += 1\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGfzfxXQ-qFy"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.30, random_state=42, stratify = Y)\n",
    "print(f'X -> training dataset size = %d, validation dataset size = %d' % (X_train.shape[0], X_val.shape[0]))\n",
    "print(f'Y -> training dataset size = %d, validation dataset size = %d' % (y_train.shape[0], y_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5qx8wR36Zxx"
   },
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "train_datagen = ImageDataGenerator(\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=10,\n",
    "    brightness_range=[0.7, 1.3]\n",
    ")\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-s10PfmEDGW"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,4, figsize=(10, 10)) \n",
    "k = 0\n",
    "imgs = next(train_generator)\n",
    "imgs_label = imgs[1]\n",
    "imgs = imgs[0]\n",
    "for i in range(4): \n",
    "    for j in range(4): \n",
    "        ax[i][j].imshow((imgs.squeeze()[k]).astype('uint8'))\n",
    "        ax[i][j].axis(\"off\")\n",
    "        ax[i][j].set_title(fac_exp[imgs_label.squeeze()[k]]) \n",
    "        k += 1\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LL7CVWXgK4xb"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 4, figsize=(25,5)) \n",
    "counts_train = collections.Counter(y_train)\n",
    "counts_val = collections.Counter(y_val)\n",
    "counts_tot = collections.Counter(Y)\n",
    "print(counts_tot)\n",
    "print(counts_train)\n",
    "print(counts_val)\n",
    "train_bar = []\n",
    "val_bar = []\n",
    "tot_bar = []\n",
    "sum_train = 0\n",
    "sum_val = 0\n",
    "sum_tot = 0\n",
    "for k in range(len(counts_tot)):\n",
    "    tot_bar.append(counts_tot[k])\n",
    "    sum_tot += counts_tot[k]\n",
    "for k in range(len(counts_train)):\n",
    "    train_bar.append(counts_train[k])\n",
    "    sum_train += counts_train[k]\n",
    "for k in range(len(counts_val)):\n",
    "    val_bar.append(counts_val[k])\n",
    "    sum_val += counts_val[k]\n",
    "ax[0].bar(fac_exp, train_bar, label = 'Training dataset')\n",
    "ax[1].bar(fac_exp, val_bar, label = 'Validation dataset')\n",
    "ax[0].set_title(\"Training\")\n",
    "ax[1].set_title(\"Validation\")\n",
    "print(f'total_entries in total =%d,train = %d, test = %d' % (sum_tot, sum_train, sum_val))\n",
    "ax[2].bar(fac_exp, tot_bar, label = 'dataset')\n",
    "ax[2].bar(fac_exp, train_bar, label = 'training')\n",
    "ax[2].bar(fac_exp, val_bar, label = 'validation')\n",
    "ax[3].pie(tot_bar, autopct='%1.1f%%',\n",
    "        shadow=True)\n",
    "ax[3].legend(loc=1, labels=fac_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCRVKzGGCSL3"
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=5)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_sparse_categorical_accuracy', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.4, \n",
    "                                            min_lr=5e-6)\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcK95hjIQ3t_"
   },
   "outputs": [],
   "source": [
    "def swish(x, beta=1.0):\n",
    "    return x * K.sigmoid(beta * x)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(48,48,1), padding='same', activation=swish, filters=32, kernel_size=(3,3)))\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 32))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 64))\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 64))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 128))\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 128))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 256))\n",
    "model.add(tf.keras.layers.Conv2D(kernel_size=(3,3), padding='same', activation=swish, filters = 256))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dropout(0.20))\n",
    "model.add(tf.keras.layers.Dense(256, activation=swish, kernel_regularizer=regularizers.l2(0.005)))\n",
    "model.add(tf.keras.layers.Dropout(0.20))\n",
    "model.add(tf.keras.layers.Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWeulANpaDmv"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    ")\n",
    "model.compile(optimizer=optimizer , loss='sparse_categorical_crossentropy', metrics='sparse_categorical_accuracy')\n",
    "epochs = 35\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=X_train.shape[0]//batch_size_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StAveK8bIkEc"
   },
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train, batch_size=64)\n",
    "y_pred_train = np.argmax(pred_train, axis=1)\n",
    "\n",
    "pred_val = model.predict(X_val, batch_size=64)\n",
    "y_pred_val = np.argmax(pred_val, axis=1)\n",
    "\n",
    "report = classification_report(y_val, \n",
    "                               y_pred_val, \n",
    "                               target_names=fac_exp, \n",
    "                               output_dict=True)\n",
    "my_df = pd.DataFrame.from_dict(report).T.round(3)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vB7F_QLQjxh8"
   },
   "outputs": [],
   "source": [
    "labels = [fac_exp[x] for x in y_val]\n",
    "pred_labels = [fac_exp[x] for x in y_pred_val]\n",
    "matrix = confusion_matrix(labels, pred_labels, fac_exp)\n",
    "my_df = pd.DataFrame(matrix, columns = fac_exp, index = fac_exp)\n",
    "\n",
    "print(\"Actual labels: \", collections.Counter(labels))\n",
    "print(\"Predicted labels: \", collections.Counter(pred_labels))\n",
    "my_df\n",
    "# True label is the i-th class and predicted label being j-th class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ew6eDf8YtVMR"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['loss'], label='loss')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('loss')\n",
    "ax.plot(history.history['val_loss'],label='val_loss')\n",
    "ax.legend(loc='upper right')\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['sparse_categorical_accuracy'], label='accuracy')\n",
    "ax.plot(history.history['val_sparse_categorical_accuracy'], label='val_accuracy')\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liJbpvqDgH9X"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/My Drive/trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LAlqsAtfBIF"
   },
   "source": [
    "CODE BELOW IS FOR THE TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJsmHvp4aImF"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "df=pd.read_csv('/content/drive/My Drive/test.csv' )\n",
    "df.head()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTkkKsgtaiXJ"
   },
   "outputs": [],
   "source": [
    "def int_pixels(X, shape=(48,48)):\n",
    "    img = [list(map(int,df['pixels'].iloc[index].split(' '))) for index in range(X.shape[0])]\n",
    "    img = np.array(img).reshape((-1, shape[0], shape[1], 1))\n",
    "    return img\n",
    "\n",
    "X_test = df.iloc[:,1:].to_numpy()\n",
    "y_test = df.iloc[:,0].to_numpy()\n",
    "# Given = (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)\n",
    "fac_exp = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Suprise\", \"Neutral\"]\n",
    "X_test = int_pixels(X_test)\n",
    "print(f\"No of pictures = %d, No of emotions = %d\" % (X_test.shape[0],y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-r0NTchKatMt"
   },
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model('/content/drive/My Drive/trained_model.h5')\n",
    "test_val = saved_model.predict(X_test, batch_size=64)\n",
    "y_pred_test = np.argmax(test_val, axis=1)\n",
    "df_test = pd.DataFrame(y_pred_test, columns=[\"classes\"])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Nkzp7aIjLsz"
   },
   "outputs": [],
   "source": [
    "df_test.to_excel(\"results.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NNFL Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
